{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topic Modelling : trouver des thèmes dans un corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Le topic modelling est un outil de machine learning non supervisé.\n",
    "\n",
    "Il permet de trouver les thèmes majeurs dans un corpus de textes, de façon automatique (ou presque)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour appliquer le topic modelling, **gensim** est la librairie de référence\n",
    "![](images/gensim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "IL faut d'abord l'installer, à l'aide de la commande suivante :\n",
    "```\n",
    "conda install -c anaconda gensim \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il existe plusieurs modèle de Topic Modelling, les plus connus sont :\n",
    "- LSA pour Latent Semantic Analysis, qui fonctionne un peu comme une analyse en composantes principales\n",
    "- LDA pour Latent Dirichlet Allocation, qui fonctionne un peu comme un K-means\n",
    "\n",
    "Nous allons ici nous focaliser sur la mise en oeuvre de la LDA, mais la méthodologie est la même pour la LSA : \n",
    "- Preprocessing des données textuelles : calcul du BOW et/ou TF-IDF\n",
    "- Entrainement du modèle (e.g. LDA ou LSA)\n",
    "- Interprétation des résultats et définition des thèmes majeurs\n",
    "- Eventuelles itérations pour affiner les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preprocessing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nous allons réutiliser le dataset des revues amazon, et calculer le TF-IDF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cd: my lovely pat has one of the great v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one of the best game music soundtracks - for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batteries died within a year ...: i bought thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but maha energy is better: check o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  class\n",
       "0  great cd: my lovely pat has one of the great v...      1\n",
       "1  one of the best game music soundtracks - for a...      1\n",
       "2  batteries died within a year ...: i bought thi...      0\n",
       "3  works fine, but maha energy is better: check o...      1\n",
       "4  great for the non-audiophile: reviewed quite a...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/amazon_reviews.csv', sep='|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "def clean_data(quote):\n",
    "    quote = quote.lower()\n",
    "    tokens = word_tokenize(quote)\n",
    "    token_punc = [t for t in tokens if t.isalpha()]\n",
    "    token_stop = [t for t in token_punc if t not in stops]\n",
    "    return token_stop\n",
    "\n",
    "# On effectue le traitement en tokens pour la suite\n",
    "df['tokens'] = df['review'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# On calcule de TF-IDF sur les 1000 premières reviews\n",
    "vectorizer = TfidfVectorizer(stop_words=stops, analyzer=lambda x: x)\n",
    "\n",
    "tfidf = vectorizer.fit_transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nous allons ensuite passer à l'étape de Topic Modelling à l'aide de gensim.\n",
    "\n",
    "La première étape est toujours la même : instancier le modèle de LDA qu'il faut importer au préalable de la façon suivante :\n",
    "```python\n",
    "from gensim.models import LdaModel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La classe `LdaModel` a la signature suivante :\n",
    "```python\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                            id2word,\n",
    "                                            num_topics, \n",
    "                                            random_state,\n",
    "                                            chunksize,\n",
    "                                            passes)\n",
    "```\n",
    "\n",
    "Avec :\n",
    "- `Corpus` le TF-IDF ou BOW (calculé avec scikit-learn)\n",
    "- `id2word` un dictionnaire avec les correspondances entre indices dans le corpus et mots (calculé par gensim)\n",
    "- `num_topics` est le nombre désiré de thèmes\n",
    "- `random_state` pour la reproductibilité (mettre toujours la même valeur)\n",
    "- `chunksize` la taille du mini-batch (laisser par défaut)\n",
    "- `passes` le nombre de fois que le modèle verra tout le corpus pour s'entrainer (1 par défaut, en général 5 ou 10 est très bien)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La seule information qui nous manque est donc le paramètre à donner en `id2word`.\n",
    "\n",
    "On peut utiliser pour ça l'objet `Dictionary`, qui s'importe de la façon suivante \n",
    "```python\n",
    "from gensim.corpora import Dictionary\n",
    "```\n",
    "\n",
    "Et qui s'applique directement sur les tokens (d'où la nécessité de le calculer au-dessus) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "id2word = Dictionary(df['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Enfin un dernier détail avant de pouvoir utiliser le modèle, il faut convertir le TF-IDF de `scikit-learn` en un format propre à `gensim` à l'aide de la fonction `Sparse2Corpus` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.matutils import Sparse2Corpus\n",
    "\n",
    "tfidf_gensim = Sparse2Corpus(tfidf, documents_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finalement, il est possible d'instancier et d'entrainer notre modèle (le tout se faisant en même temps) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# On instancie et entraine un modèle qui trouvera 3 thèmes\n",
    "lda = LdaModel(corpus=tfidf_gensim, id2word=id2word, num_topics=3, random_state=0, passes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il est maintenant possible d'afficher les thèmes majeurs, avec la méthode `.print_topics()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.001*\"marvalettes\" + 0.001*\"hardwood\" + 0.000*\"portwe\" + 0.000*\"subtle\" + '\n",
      "  '0.000*\"projects\" + 0.000*\"apes\" + 0.000*\"spins\" + 0.000*\"luce\" + '\n",
      "  '0.000*\"epilator\" + 0.000*\"deviating\"'),\n",
      " (1,\n",
      "  '0.004*\"marky\" + 0.003*\"flange\" + 0.002*\"rack\" + 0.002*\"remixed\" + '\n",
      "  '0.002*\"meyer\" + 0.002*\"sansui\" + 0.002*\"meaningful\" + 0.002*\"sequel\" + '\n",
      "  '0.002*\"lencioni\" + 0.002*\"unsullied\"'),\n",
      " (2,\n",
      "  '0.007*\"breakthrough\" + 0.005*\"thumbprint\" + 0.004*\"lencioni\" + '\n",
      "  '0.004*\"endorse\" + 0.003*\"meaningful\" + 0.003*\"rack\" + 0.003*\"supplemental\" '\n",
      "  '+ 0.002*\"typewritter\" + 0.002*\"sansui\" + 0.002*\"breakdowns\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(lda.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'idée est ensuite d'interpréter ces résultats..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Il existe une librairie dédiée de visualisation des résultats de LDA, nommée `pyLDAvis`.\n",
    "\n",
    "Cette dernière doit au préalable être installée avec la commande suivante :\n",
    "```\n",
    "conda install -c conda-forge pyldavis \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "L'utilisation est ensuite relativement simple, il suffit ensuite d'effectuer quelques imports et lignes de code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "bow = [id2word.doc2bow(line) for line in df['tokens']]  # convert corpus to BoW format\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda, dictionary=id2word, corpus=bow)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "\n",
    "Appliquer le topic modelling au dataset `headlines.csv`, qui contient des titres de journaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/headlines.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
